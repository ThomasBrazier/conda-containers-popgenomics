{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build and deploy reproducible environments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been produced for a mini workshop about Conda and Docker. It was presented as a seminar for the evo-adapt scientific animation.\n",
    "\n",
    "January 31th 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Install conda](https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html)\n",
    "\n",
    "[Install Docker](https://docs.docker.com/engine/install/)\n",
    "\n",
    "[Install Singularity](https://anaconda.org/conda-forge/singularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install with `conda`\n",
    "\n",
    "`conda` is a package manager, mostly known in the `python` programming community (historically it is a package manager for Python packages), but it is now widely used in bio-informatics and can be used to install a large number of softwares with C, C++, Python, R dependencies.\n",
    "\n",
    "Conda installs virtual environments. They are installed in a `~/.conda` directory per default, though it can be configured to be your working directory, or any other directory that makes sense to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 124K\n",
      "drwxr-xr-x.   4 tbrazier UR1 4,0K 10 oct.  17:22 .\n",
      "drwx------.  45 tbrazier UR1 4,0K 27 janv. 17:43 ..\n",
      "-rw-r--r--.   1 tbrazier UR1  806 27 janv. 18:12 environments.txt\n",
      "drwxrwsr-x.  14 tbrazier UR1 4,0K 27 janv. 15:24 envs\n",
      "drwxrwsr-x. 718 tbrazier UR1 104K 27 janv. 18:12 pkgs\n",
      "total 56K\n",
      "drwxrwsr-x. 14 tbrazier UR1 4,0K 27 janv. 15:24 .\n",
      "drwxr-xr-x.  4 tbrazier UR1 4,0K 10 oct.  17:22 ..\n",
      "drwxr-sr-x. 15 tbrazier UR1 4,0K 21 janv. 11:39 bcftools\n",
      "-rw-r--r--.  1 tbrazier UR1    0 10 oct.  17:22 .conda_envs_dir_test\n",
      "drwxr-sr-x.  8 tbrazier UR1 4,0K 17 déc.  14:44 goat\n",
      "drwxr-sr-x. 17 tbrazier UR1 4,0K  4 janv. 13:17 herho\n",
      "drwxr-sr-x. 17 tbrazier UR1 4,0K 16 janv. 14:13 jasminesv\n",
      "total 80M\n",
      "drwxrwsr-x. 718 tbrazier UR1 104K 27 janv. 18:12 .\n",
      "drwxr-xr-x.   4 tbrazier UR1 4,0K 10 oct.  17:22 ..\n",
      "drwxr-sr-x.   7 tbrazier UR1 4,0K 10 oct.  17:30 alsa-lib-1.2.12-h4ab18f5_0\n",
      "drwxr-sr-x.   7 tbrazier UR1 4,0K  4 janv. 11:10 alsa-lib-1.2.13-hb9d3cd8_0\n",
      "drwxr-sr-x.   4 tbrazier UR1 4,0K 20 janv. 14:30 anaconda-client-1.12.3-pyhd8ed1ab_1\n",
      "drwxr-sr-x.   4 tbrazier UR1 4,0K 20 janv. 17:18 anyio-4.6.2-py312h06a4308_0\n",
      "drwxr-sr-x.   4 tbrazier UR1 4,0K 10 oct.  17:36 apricot-select-0.6.1-pyhd8ed1ab_0\n",
      "ls: erreur d'écriture: Relais brisé (pipe)\n"
     ]
    }
   ],
   "source": [
    "!ls -lha ~/.conda\n",
    "\n",
    "# Virtual envs are in separate directories in `~/.conda/envs/`\n",
    "!ls -lha ~/.conda/envs/ | head -n 8\n",
    "\n",
    "# Package binaries are downloaded and stored in separate directories in `~/.conda/pkgs/`\n",
    "!ls -lha ~/.conda/pkgs/ | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't have to bother about these directories. You manage all your packages and envs through conda commands. Each `conda <command>` has a specific purpose and set of options. The most used commands are `conda create`, `conda install`, `conda remove` and `conda clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "\n",
      "conda is a tool for managing and deploying applications, environments and packages.\n",
      "\n",
      "options:\n",
      "  -h, --help            Show this help message and exit.\n",
      "  -v, --verbose         Can be used multiple times. Once for detailed output,\n",
      "                        twice for INFO logging, thrice for DEBUG logging, four\n",
      "                        times for TRACE logging.\n",
      "  --no-plugins          Disable all plugins that are not built into conda.\n",
      "  -V, --version         Show the conda version number and exit.\n",
      "\n",
      "commands:\n",
      "  The following built-in and plugins subcommands are available.\n",
      "\n",
      "  COMMAND\n",
      "    activate            Activate a conda environment.\n",
      "    build               Build conda packages from a conda recipe.\n",
      "    clean               Remove unused packages and caches.\n",
      "    commands            List all available conda subcommands (including those\n",
      "                        from plugins). Generally only used by tab-completion.\n",
      "    compare             Compare packages between conda environments.\n",
      "    config              Modify configuration values in .condarc.\n",
      "    convert             Convert pure Python packages to other platforms\n",
      "                        (a.k.a., subdirs).\n",
      "    create              Create a new conda environment from a list of\n",
      "                        specified packages.\n",
      "    deactivate          Deactivate the current active conda environment.\n",
      "    debug               Debug the build or test phases of conda recipes.\n",
      "    develop             Install a Python package in 'development mode'.\n",
      "                        Similar to `pip install --editable`.\n",
      "    doctor              Display a health report for your environment.\n",
      "    export              Export a given environment\n",
      "    index               Update package index metadata files.\n",
      "    info                Display information about current conda install.\n",
      "    init                Initialize conda for shell interaction.\n",
      "    inspect             Tools for inspecting conda packages.\n",
      "    install             Install a list of packages into a specified conda\n",
      "                        environment.\n",
      "    list                List installed packages in a conda environment.\n",
      "    metapackage         Specialty tool for generating conda metapackage.\n",
      "    notices             Retrieve latest channel notifications.\n",
      "    package             Create low-level conda packages. (EXPERIMENTAL)\n",
      "    remove (uninstall)  Remove a list of packages from a specified conda\n",
      "                        environment.\n",
      "    rename              Rename an existing environment.\n",
      "    render              Expand a conda recipe into a platform-specific recipe.\n",
      "    repoquery           Advanced search for repodata.\n",
      "    run                 Run an executable in a conda environment.\n",
      "    search              Search for packages and display associated information\n",
      "                        using the MatchSpec format.\n",
      "    server              See `conda server --help`.\n",
      "    skeleton            Generate boilerplate conda recipes.\n",
      "    update (upgrade)    Update conda packages to the latest compatible\n",
      "                        version.\n"
     ]
    }
   ],
   "source": [
    "# conda commands\n",
    "!conda --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbrazier/.conda/envs/jupyterlab/lib/python3.12/site-packages/conda/base/context.py:202: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
      "\n",
      "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
      "\n",
      "  conda config --add channels defaults\n",
      "\n",
      "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
      "\n",
      "  deprecated.topic(\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... "
     ]
    }
   ],
   "source": [
    "# Create a new virtual env\n",
    "!conda create --yes --quiet -c conda-forge --name workshop python=3.11 # Can be long, conda is not fast\n",
    "!conda init\n",
    "!source activate workshop\n",
    "\n",
    "# Install a package\n",
    "!conda install -y -q numpy\n",
    "\n",
    "# Remove a package\n",
    "!conda remove -y numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manage your conda envs with `conda env <command>`. It is much easier than using directly `conda` commands and allows you to use `.yaml` file to define your future virtual env. This `yaml` file is crucial to keep a trace of what has been installed in your env and to replicate it automatically in another machine/user.\n",
    "\n",
    "A `yaml` is a basic human-readable markup language. It has a simple structure used to define/setup the virtual env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Example of a basic yaml file for conda env\n",
    "name: workshop-test-1 # the name of the virtual env\n",
    "channels: # The conda channels where to look for packages\n",
    "    - conda-forge\n",
    "dependencies: # Packages to install\n",
    "    - python=3.7 # Specify the required version\n",
    "    - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda env [-h] command ...\n",
      "\n",
      "positional arguments:\n",
      "  command\n",
      "    config    Configure a conda environment.\n",
      "    create    Create an environment based on an environment definition file.\n",
      "    export    Export a given environment\n",
      "    list      An alias for `conda info --envs`. Lists all conda environments.\n",
      "    remove    Remove an environment.\n",
      "    update    Update the current environment based on environment file.\n",
      "\n",
      "options:\n",
      "  -h, --help  Show this help message and exit.\n"
     ]
    }
   ],
   "source": [
    "!conda env --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Create a conda virtual env from a file\n",
    "!conda env create -q -f workshop-test-1.yaml\n",
    "\n",
    "# Update with a new package\n",
    "!conda env update -q -f workshop-test-2.yaml\n",
    "\n",
    "!conda env remove -n workshop-test-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have installed your `conda` packages, it is good practice to do `conda clean` to remove all cached tarballs and unused packages (remember, they are in `~/.conda/pkgs/). These packages are decompressed in a lot of small files and you can have quota issues on a cluster due to all these files.\n",
    "\n",
    "Note that having all your envs defined in `yaml` files is really a time-saver. You can safely remove envs on your cluster to save space and recompile them easily when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will remove 324 (726.7 MB) tarball(s).\n",
      "Will remove 2 index cache(s).\n",
      "Will remove 210 (1.43 GB) package(s).\n",
      "^C\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda clean -y --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to find packages. Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Anaconda](https://anaconda.org/conda-forge) website is a catalogue of all `conda` packages available. Note that `Anaconda` is not `conda`. `Anaconda` is a package provider with a free license only for non commercial use (if you use the `anaconda` channel). However, we usually stay with `conda-forge` or `bioconda` channels, which are totally free. `bioconda` contains a lot of additional bio-informatics packages.\n",
    "\n",
    "![An overview of the Anaconda website](https://europe1.discourse-cdn.com/anaconda/original/2X/b/beba40e0306afb252446c553c9c6670a106ab3ab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced. Complex conda env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `conda env` and `yaml` files you can configure complex environments. You can include `pip` packages (another Python package manager), `R` packages, `C` libraries, Unix command line softwares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Example of a complex yaml file for conda env\n",
      "name: workshop-test-complex # the name of the virtual env\n",
      "channels:\n",
      "  - mamba\n",
      "  - conda-forge\n",
      "  - bioconda\n",
      "dependencies:\n",
      "  - git # Unix software\n",
      "  - r-base # R\n",
      "  - jq\n",
      "  - bcftools # bioinformatic software\n",
      "  - vcftools # bioinformatic software\n",
      "  - samtools # bioinformatic software\n",
      "  - htslib # bioinformatic library\n",
      "  - blas\n",
      "  - cyvcf2\n",
      "  - gsl # GNU scientific library in C\n",
      "  - openssl>1.0 # Unix software\n",
      "  - pip # pip package manager\n",
      "  - python=3.8\n",
      "  - pip: # install with pip - not in conda or dependencies for github installs\n",
      "    - cython\n",
      "    - msprime\n",
      "    - numba\n",
      "    - numpy\n",
      "    - scikit-learn\n",
      "    - pandas\n",
      "    - \"--editable=git+https://github.com/popgenmethods/ldpop.git#egg=ldpop\" # Install directly from github\n",
      "    - tskit\n",
      "    - \"--editable=git+https://github.com/popgenmethods/pyrho.git#egg=pyrho\" # Install directly from github\n"
     ]
    }
   ],
   "source": [
    "!cat workshop-test-3.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced. Create your own conda recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have a new package you want to publish, or the package you need is not in a `conda` forge, cannot be installed or require some bugfixes or new features you want to implement.\n",
    "\n",
    "There is a solution to stay with `conda` (and you want to stay as much as possible with the same package manager). You can code your own conda recipe. `conda` forges are freely accessible, and you can push your conda recipe to `https://anaconda.org`. Your recipe can remain private or public. For example, I needed the `rCNV` R package, which has no `conda install`. I created a `conda` recipe on my own and pushed it to `https://anaconda.org` so it can be installed simply with `conda install tbrazier::r-rcnv`. In fact, it is relatively easy to put R packages that are already in the CRAN in a `conda` recipe. Look below how I created the `conda` recipe for this R package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Get the CRAN repository and build a skeleton\n",
    "!conda skeleton cran rCNV\n",
    "\n",
    "# Build the package and store the output path\n",
    "!conda build --build-only -c conda-forge -c bioconda r-rcnv/. --output > conda_path\n",
    "\n",
    "# Push to anaconda as tbrazier::r-rcnv\n",
    "# To upload to anaconda, you need to be logged in. See https://docs.anaconda.com/anacondaorg/\n",
    "# Look the package https://anaconda.org/tbrazier/r-rcnv\n",
    "!anaconda upload $(cat conda_path)\n",
    "\n",
    "# Cleaning\n",
    "!conda build purge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the package is not a R package in the CRAN, you have to manually set up the `meta.yaml`. See below for the `ngsParalog` software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package:\n",
      "  name: ngsparalog\n",
      "  version: 1.3.3\n",
      "\n",
      "build:\n",
      "  script:\n",
      "    - git clone --branch v1.3.3 https://github.com/tplinderoth/ngsParalog\n",
      "    - cd ngsParalog\n",
      "    - make\n",
      "    - make clean\n",
      "\n",
      "requirements:\n",
      "  build:\n",
      "    - make\n",
      "    - git\n",
      "    - htslib\n",
      "    - samtools\n",
      "    - numpy=1.23\n",
      "  run:\n",
      "    - python\n",
      "    - htslib\n",
      "    - samtools\n",
      "    - r-truncnorm\n",
      "    - r-docopt\n",
      "\n",
      "\n",
      "about:\n",
      "  home: https://github.com/tplinderoth/ngsParalog\n",
      "  license: GPL-3.0\n",
      "  summary: 'Copy number variation detection using NGS data'\n",
      "  description: |\n",
      "    ngsParalog is a program for detecting genomic regions that are problematic for short reading mapping using population-level, next generation sequencing (NGS) data.\n",
      "  dev_url: https://github.com/tplinderoth/ngsParalog\n",
      "  doc_url: https://github.com/tplinderoth/ngsParalog\n",
      "  doc_source_url: https://github.com/tplinderoth/ngsParalog/blob/master/README.md"
     ]
    }
   ],
   "source": [
    "!cat ngsParalog/meta.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the package and store the output path\n",
    "!conda build --build-only -c conda-forge -c bioconda ngsParalog/. --output > conda_path\n",
    "\n",
    "# Push to anaconda as tbrazier::r-rcnv\n",
    "# To upload to anaconda, you need to be logged in. See https://docs.anaconda.com/anacondaorg/\n",
    "# Look the package https://anaconda.org/tbrazier/r-rcnv\n",
    "!anaconda upload $(cat conda_path)\n",
    "\n",
    "# Cleaning\n",
    "!conda build purge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a container (with `Docker`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a docker, you must describe the architecture and content of the docker in a definition file. It is a markup format, similar to `yaml`. Usually the docker definition file is simply named `Dockerfile`. For Singularity, definition files have the suffix `.def`. After the build, Docker/Singularity saves your application as an image stored by your container manager (you will not see it in your working directory). I prefer to code and build containers with Docker, because I find it easier and there are more resources to get help. Utlimately it is not important if you use either Docker of Singularity, as both produce images with Singularity at hte next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Build locally (the Dockerfile is in the directory)\n",
    "# Add the tag <user>/<dockername>:<version>\n",
    "!sudo docker build -t tombrazier/ldhat:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is as simple as that to build! Now look at the definition file... It is very close to what you would do to install it on a unix system to install, except that each command is put in a layer, such as `RUN`, `USER`, `ENV` or `WORKDIR`.\n",
    "\n",
    "We check that the docker image is well saved on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# See all images, even non running\n",
    "!sudo docker ps -a\n",
    "\n",
    "# Run an interactive shell within the container\n",
    "!sudo docker container run -it tombrazier/ldhat bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your image is built in your system, you can push it to an application catalogue, where it will be available for other users and yourself. The best choice is probably Dockerhub (https://hub.docker.com/), which is similar to the anaconda repository, but for containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "!sudo docker image tag tombrazier/ldhat:latest tombrazier/ldhat:v2\n",
    "!sudo docker image push tombrazier/ldhat:v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull a container (with `Singularity`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, you will find an existing docker for your application, and you will just have to pull the image. Otherwise, you have seen how to build an image and push it to a Docker catalogue (Dockerhub).\n",
    "\n",
    "We will play with the `minimap2` docker from the `Biocontainers` project (see https://biocontainers.pro/tools/minimap2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Get Minimap2 from Biocontainers registry\n",
    "!singularity pull minimap2.sif docker://quay.io/biocontainers/minimap2:2.28--h577a1d6_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The containerized appplication is now saved as a `.sif` image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the container (with `Singularity`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In singularity, `exec` is used to run a command. The container stops once the command is finished.\n",
    "\n",
    "`shell` is used to launch an interactive shell within the container. It is particularly useful to navigate within container directories and debug containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# by default, singularity shell bind the current directory\n",
    "!singularity exec minimap2.sif pwd\n",
    "!singularity exec minimap2.sif echo $USER\n",
    "!singularity exec minimap2.sif minimap2\n",
    "\n",
    "# Run an interactive shell to play with the docker\n",
    "!singularity shell minimap2.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced. Binding directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singularity documentation. \"When Singularity ‘swaps’ the host operating system for the one inside your container, the host file systems becomes inaccessible. But you may want to read and write files on the host system from within the container.\"\n",
    "\n",
    "See https://docs.sylabs.io/guides/3.0/user-guide/bind_paths_and_mounts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is in the local directory\n",
      "total 715M\n",
      "-rw-r--r--. 1 tbrazier UR1  26K 20 janv. 16:55 build-deploy-softwares.ipynb\n",
      "-rw-r--r--. 1 tbrazier UR1    0 20 janv. 14:43 conda_path\n",
      "-rwxr-xr-x. 1 tbrazier UR1 1,4K 20 janv. 15:14 Dockerfile\n",
      "-rwxr-xr-x. 1 tbrazier UR1 263M 20 janv. 15:38 ldhat.sif\n",
      "-rwxr-xr-x. 1 tbrazier UR1  58M 20 janv. 16:30 minimap2.sif\n",
      "-rwxr-xr-x. 1 tbrazier UR1 394M 20 janv. 15:57 pyrho.sif\n",
      "-rw-r--r--. 1 tbrazier UR1   91 20 janv. 11:47 python-notebook.yaml\n",
      "drwxr-xr-x. 2 tbrazier UR1 4,0K 20 janv. 14:20 r-rcnv\n",
      "-rw-r--r--. 1 tbrazier UR1  237 20 janv. 12:44 workshop-test-1.yaml\n",
      "-rw-r--r--. 1 tbrazier UR1  271 20 janv. 12:45 workshop-test-2.yaml\n",
      "-rw-r--r--. 1 tbrazier UR1  886 20 janv. 12:58 workshop-test-3.yaml\n",
      "The local directory mounted in the /mnt container directory\n",
      "total 715M   \n",
      "-rwxr-xr-x    1 tbrazier UR1         1.4K Jan 20 15:14 \u001b[1;32mDockerfile\u001b[m\n",
      "-rw-r--r--    1 tbrazier UR1        25.7K Jan 20 16:55 \u001b[0;0mbuild-deploy-softwares.ipynb\u001b[m\n",
      "-rw-r--r--    1 tbrazier UR1            0 Jan 20 14:43 \u001b[0;0mconda_path\u001b[m\n",
      "-rwxr-xr-x    1 tbrazier UR1       263.0M Jan 20 15:38 \u001b[1;32mldhat.sif\u001b[m\n",
      "-rwxr-xr-x    1 tbrazier UR1        57.9M Jan 20 16:30 \u001b[1;32mminimap2.sif\u001b[m\n",
      "-rwxr-xr-x    1 tbrazier UR1       393.7M Jan 20 15:57 \u001b[1;32mpyrho.sif\u001b[m\n",
      "-rw-r--r--    1 tbrazier UR1           91 Jan 20 11:47 \u001b[0;0mpython-notebook.yaml\u001b[m\n",
      "drwxr-xr-x    2 tbrazier UR1         4.0K Jan 20 14:20 \u001b[1;34mr-rcnv\u001b[m\n",
      "-rw-r--r--    1 tbrazier UR1          237 Jan 20 12:44 \u001b[0;0mworkshop-test-1.yaml\u001b[m\n",
      "-rw-r--r--    1 tbrazier UR1          271 Jan 20 12:45 \u001b[0;0mworkshop-test-2.yaml\u001b[m\n",
      "-rw-r--r--    1 tbrazier UR1          886 Jan 20 12:58 \u001b[0;0mworkshop-test-3.yaml\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!echo 'What is in the local directory'\n",
    "!ls -lh\n",
    "\n",
    "!echo 'The local directory mounted in the /mnt container directory'\n",
    "!singularity exec --bind $PWD:/mnt minimap2.sif ls -lh /mnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is really important to bind directories when you want to modify files in your local directories and that files produced during `singularity exec` are not lost when the container stop.\n",
    "\n",
    "Compare this two commands that look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local directory mounted in the /mnt container directory\n",
      "touch: /mnt/test-nobind: Read-only file system\n",
      "total 0\n",
      "total 0\n",
      "The local directory mounted in the /mnt container directory\n",
      "total 731772\n",
      "-rw-r--r--. 1 tbrazier UR1     30722 20 janv. 17:03 build-deploy-softwares.ipynb\n",
      "-rw-r--r--. 1 tbrazier UR1         0 20 janv. 14:43 conda_path\n",
      "-rwxr-xr-x. 1 tbrazier UR1      1390 20 janv. 15:14 Dockerfile\n",
      "-rwxr-xr-x. 1 tbrazier UR1 275746816 20 janv. 15:38 ldhat.sif\n",
      "-rwxr-xr-x. 1 tbrazier UR1  60669952 20 janv. 16:30 minimap2.sif\n",
      "-rwxr-xr-x. 1 tbrazier UR1 412848128 20 janv. 15:57 pyrho.sif\n",
      "-rw-r--r--. 1 tbrazier UR1        91 20 janv. 11:47 python-notebook.yaml\n",
      "drwxr-xr-x. 2 tbrazier UR1      4096 20 janv. 14:20 r-rcnv\n",
      "-rw-r--r--. 1 tbrazier UR1         0 20 janv. 17:03 test-bind\n",
      "-rw-r--r--. 1 tbrazier UR1       237 20 janv. 12:44 workshop-test-1.yaml\n",
      "-rw-r--r--. 1 tbrazier UR1       271 20 janv. 12:45 workshop-test-2.yaml\n",
      "-rw-r--r--. 1 tbrazier UR1       886 20 janv. 12:58 workshop-test-3.yaml\n"
     ]
    }
   ],
   "source": [
    "!echo 'The local directory mounted in the /mnt container directory'\n",
    "!singularity exec minimap2.sif touch /mnt/test-nobind\n",
    "!singularity exec minimap2.sif ls -l /mnt # Containers are really immutable. The file test-nobind is not saved, container is not modified\n",
    "!ls -l /mnt\n",
    "\n",
    "!echo 'The local directory mounted in the /mnt container directory'\n",
    "!singularity exec --bind $PWD:/mnt minimap2.sif touch /mnt/test-bind\n",
    "\n",
    "!ls -l\n",
    "# test-bind does exist, but not test-nobind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
